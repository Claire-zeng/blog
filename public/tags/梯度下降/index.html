<!DOCTYPE html>
<html lang="zh-cn">
<head><script src="/blog/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=blog/livereload" data-no-instant defer></script>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>梯度下降 - Claire的技术学习笔记</title>
    
    
    <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\\(', '\\)']],
                displayMath: [['$$', '$$'], ['\\[', '\\]']],
                processEscapes: true,
                processEnvironments: true
            },
            options: {
                skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
            },
            chtml: {
                linebreaks: { automatic: true }
            }
        };
    </script>
    
    
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    
    
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-tomorrow.min.css" rel="stylesheet" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>
    
    
    <link rel="stylesheet" href="http://localhost:1313/blog/css/style.css">
    
    
    <link rel="icon" type="image/x-icon" href="http://localhost:1313/blog/favicon.ico">
</head>
<body>
    <header class="site-header">
        <div class="container">
            <nav class="navbar">
                <div class="navbar-brand">
                    <a href="http://localhost:1313/blog/" class="navbar-item">
                        <h1 class="title">Claire的技术学习笔记</h1>
                    </a>
                </div>
                <div class="navbar-menu">
                    <a href="http://localhost:1313/blog/" class="navbar-item">首页</a>
                    <a href="http://localhost:1313/blog/categories" class="navbar-item">分类</a>
                    <a href="http://localhost:1313/blog/tags" class="navbar-item">标签</a>
                    <a href="http://localhost:1313/blog/about" class="navbar-item">关于</a>
                </div>
            </nav>
        </div>
    </header>

    <main class="site-main">
        <div class="container">
            
<div class="list-page">
    <header class="page-header">
        <h1 class="page-title">
            
                标签：梯度下降
            
        </h1>
        
    </header>

    <div class="posts-list">
        
        <article class="post-item">
            <div class="post-meta">
                <time datetime="2024-01-15">2024年1月15日</time>
                
                <span class="category">数值优化</span>
                
            </div>
            <h2 class="post-title">
                <a href="/blog/posts/gradient-descent/">梯度下降算法详解</a>
            </h2>
            <p class="post-excerpt"><h1 id="梯度下降算法详解">梯度下降算法详解</h1>
<p>梯度下降是数值优化中最基础和重要的算法之一。本文将详细介绍梯度下降的原理、实现和应用。</p>
<h2 id="算法原理">算法原理</h2>
<p>梯度下降的核心思想是沿着目标函数的负梯度方向进行搜索，以找到函数的局部最小值。</p>
<p>对于目标函数 $f(x)$，梯度下降的更新公式为：</p>
<p>$$x_{k+1} = x_k - \alpha \nabla f(x_k)$$</p>
<p>其中：</p>
<ul>
<li>$x_k$ 是第 $k$ 次迭代的参数值</li>
<li>$\alpha$ 是学习率</li>
<li>$\nabla f(x_k)$ 是函数在 $x_k$ 处的梯度</li>
</ul>
<h2 id="代码实现">代码实现</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">gradient_descent</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">grad_f</span><span class="p">,</span> <span class="n">x0</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;&#34;&#34;
</span></span></span><span class="line"><span class="cl"><span class="s2">    梯度下降算法实现
</span></span></span><span class="line"><span class="cl"><span class="s2">    
</span></span></span><span class="line"><span class="cl"><span class="s2">    参数:
</span></span></span><span class="line"><span class="cl"><span class="s2">    f: 目标函数
</span></span></span><span class="line"><span class="cl"><span class="s2">    grad_f: 梯度函数
</span></span></span><span class="line"><span class="cl"><span class="s2">    x0: 初始点
</span></span></span><span class="line"><span class="cl"><span class="s2">    alpha: 学习率
</span></span></span><span class="line"><span class="cl"><span class="s2">    max_iter: 最大迭代次数
</span></span></span><span class="line"><span class="cl"><span class="s2">    tol: 收敛容差
</span></span></span><span class="line"><span class="cl"><span class="s2">    
</span></span></span><span class="line"><span class="cl"><span class="s2">    返回:
</span></span></span><span class="line"><span class="cl"><span class="s2">    x: 最优解
</span></span></span><span class="line"><span class="cl"><span class="s2">    history: 迭代历史
</span></span></span><span class="line"><span class="cl"><span class="s2">    &#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">x0</span>
</span></span><span class="line"><span class="cl">    <span class="n">history</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="o">.</span><span class="n">copy</span><span class="p">()]</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_iter</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="n">grad</span> <span class="o">=</span> <span class="n">grad_f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">x_new</span> <span class="o">=</span> <span class="n">x</span> <span class="o">-</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">grad</span>
</span></span><span class="line"><span class="cl">        
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">x_new</span> <span class="o">-</span> <span class="n">x</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">tol</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="k">break</span>
</span></span><span class="line"><span class="cl">            
</span></span><span class="line"><span class="cl">        <span class="n">x</span> <span class="o">=</span> <span class="n">x_new</span>
</span></span><span class="line"><span class="cl">        <span class="n">history</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">copy</span><span class="p">())</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">x</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">history</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 示例：最小化 f(x) = x^2 + 2x + 1</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">x</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="mi">2</span><span class="o">*</span><span class="n">x</span> <span class="o">+</span> <span class="mi">1</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">grad_f</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="mi">2</span><span class="o">*</span><span class="n">x</span> <span class="o">+</span> <span class="mi">2</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 运行梯度下降</span>
</span></span><span class="line"><span class="cl"><span class="n">x_opt</span><span class="p">,</span> <span class="n">history</span> <span class="o">=</span> <span class="n">gradient_descent</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">grad_f</span><span class="p">,</span> <span class="n">x0</span><span class="o">=</span><span class="mf">5.0</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;最优解: x = </span><span class="si">{</span><span class="n">x_opt</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;最优值: f(x) = </span><span class="si">{</span><span class="n">f</span><span class="p">(</span><span class="n">x_opt</span><span class="p">)</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span></code></pre></div><h2 id="收敛性分析">收敛性分析</h2>
<p>梯度下降的收敛性取决于以下几个因素：</p></p>
            <div class="post-tags">
                
                <span class="tag">梯度下降</span>
                
                <span class="tag">机器学习</span>
                
                <span class="tag">一阶优化</span>
                
                <span class="tag">收敛性分析</span>
                
            </div>
        </article>
        
    </div>
</div>

        </div>
    </main>

    <footer class="site-footer">
        <div class="container">
            <p>&copy; 2025 Claire的技术学习笔记. All rights reserved.</p>
        </div>
    </footer>

    
    <button id="back-to-top" class="back-to-top-btn" title="回到顶部">
        <svg width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg">
            <path d="M12 4L4 12H8V20H16V12H20L12 4Z" fill="currentColor"/>
        </svg>
    </button>

    
    <script>
        document.addEventListener('DOMContentLoaded', function() {
            const backToTopBtn = document.getElementById('back-to-top');
            
            
            window.addEventListener('scroll', function() {
                if (window.pageYOffset > 300) {
                    backToTopBtn.classList.add('show');
                } else {
                    backToTopBtn.classList.remove('show');
                }
            });
            
            
            backToTopBtn.addEventListener('click', function() {
                window.scrollTo({
                    top: 0,
                    behavior: 'smooth'
                });
            });
        });
    </script>
</body>
</html>
