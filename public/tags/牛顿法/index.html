<!DOCTYPE html>
<html lang="zh-cn">
<head><script src="/blog/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=blog/livereload" data-no-instant defer></script>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>牛顿法 - Claire的技术学习笔记</title>
    
    
    <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\\(', '\\)']],
                displayMath: [['$$', '$$'], ['\\[', '\\]']],
                processEscapes: true,
                processEnvironments: true
            },
            options: {
                skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
            },
            chtml: {
                linebreaks: { automatic: true }
            }
        };
    </script>
    
    
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    
    
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-tomorrow.min.css" rel="stylesheet" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>
    
    
    <link rel="stylesheet" href="http://localhost:1313/blog/css/style.css">
    
    
    <link rel="icon" type="image/x-icon" href="http://localhost:1313/blog/favicon.ico">
</head>
<body>
    <header class="site-header">
        <div class="container">
            <nav class="navbar">
                <div class="navbar-brand">
                    <a href="http://localhost:1313/blog/" class="navbar-item">
                        <h1 class="title">Claire的技术学习笔记</h1>
                    </a>
                </div>
                <div class="navbar-menu">
                    <a href="http://localhost:1313/blog/" class="navbar-item">首页</a>
                    <a href="http://localhost:1313/blog/categories" class="navbar-item">分类</a>
                    <a href="http://localhost:1313/blog/tags" class="navbar-item">标签</a>
                    <a href="http://localhost:1313/blog/about" class="navbar-item">关于</a>
                </div>
            </nav>
        </div>
    </header>

    <main class="site-main">
        <div class="container">
            
<div class="list-page">
    <header class="page-header">
        <h1 class="page-title">
            
                标签：牛顿法
            
        </h1>
        
    </header>

    <div class="posts-list">
        
        <article class="post-item">
            <div class="post-meta">
                <time datetime="2024-01-16">2024年1月16日</time>
                
                <span class="category">数值优化</span>
                
            </div>
            <h2 class="post-title">
                <a href="/blog/posts/newton-method/">牛顿法优化算法</a>
            </h2>
            <p class="post-excerpt"><h1 id="牛顿法优化算法">牛顿法优化算法</h1>
<p>牛顿法是一种基于二阶信息的优化算法，相比梯度下降具有更快的收敛速度。</p>
<h2 id="算法原理">算法原理</h2>
<p>牛顿法利用函数的二阶导数信息来构造更好的搜索方向。对于目标函数 $f(x)$，牛顿法的更新公式为：</p>
<p>$$x_{k+1} = x_k - H^{-1}(x_k) \nabla f(x_k)$$</p>
<p>其中：</p>
<ul>
<li>$H(x_k)$ 是函数在 $x_k$ 处的Hessian矩阵</li>
<li>$\nabla f(x_k)$ 是梯度向量</li>
</ul>
<h2 id="优势与特点">优势与特点</h2>
<ol>
<li><strong>二次收敛</strong>：在最优解附近具有二次收敛速度</li>
<li><strong>二阶信息</strong>：利用Hessian矩阵提供更精确的局部信息</li>
<li><strong>自适应步长</strong>：不需要手动设置学习率</li>
</ol>
<h2 id="代码实现">代码实现</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">scipy.linalg</span> <span class="kn">import</span> <span class="n">inv</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">newton_method</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">grad_f</span><span class="p">,</span> <span class="n">hess_f</span><span class="p">,</span> <span class="n">x0</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;&#34;&#34;
</span></span></span><span class="line"><span class="cl"><span class="s2">    牛顿法实现
</span></span></span><span class="line"><span class="cl"><span class="s2">    
</span></span></span><span class="line"><span class="cl"><span class="s2">    参数:
</span></span></span><span class="line"><span class="cl"><span class="s2">    f: 目标函数
</span></span></span><span class="line"><span class="cl"><span class="s2">    grad_f: 梯度函数
</span></span></span><span class="line"><span class="cl"><span class="s2">    hess_f: Hessian函数
</span></span></span><span class="line"><span class="cl"><span class="s2">    x0: 初始点
</span></span></span><span class="line"><span class="cl"><span class="s2">    max_iter: 最大迭代次数
</span></span></span><span class="line"><span class="cl"><span class="s2">    tol: 收敛容差
</span></span></span><span class="line"><span class="cl"><span class="s2">    &#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">x0</span>
</span></span><span class="line"><span class="cl">    <span class="n">history</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="o">.</span><span class="n">copy</span><span class="p">()]</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_iter</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="n">grad</span> <span class="o">=</span> <span class="n">grad_f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">hess</span> <span class="o">=</span> <span class="n">hess_f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        
</span></span><span class="line"><span class="cl">        <span class="c1"># 求解线性方程组 H(x) * d = -grad(x)</span>
</span></span><span class="line"><span class="cl">        <span class="k">try</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">d</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">hess</span><span class="p">,</span> <span class="o">-</span><span class="n">grad</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="k">except</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">LinAlgError</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># 如果Hessian不可逆，使用伪逆</span>
</span></span><span class="line"><span class="cl">            <span class="n">d</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">pinv</span><span class="p">(</span><span class="n">hess</span><span class="p">)</span> <span class="o">@</span> <span class="n">grad</span>
</span></span><span class="line"><span class="cl">        
</span></span><span class="line"><span class="cl">        <span class="n">x_new</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">d</span>
</span></span><span class="line"><span class="cl">        
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">x_new</span> <span class="o">-</span> <span class="n">x</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">tol</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="k">break</span>
</span></span><span class="line"><span class="cl">            
</span></span><span class="line"><span class="cl">        <span class="n">x</span> <span class="o">=</span> <span class="n">x_new</span>
</span></span><span class="line"><span class="cl">        <span class="n">history</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">copy</span><span class="p">())</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">x</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">history</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 示例：最小化 f(x) = x^2 + 2x + 1</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">x</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="mi">2</span><span class="o">*</span><span class="n">x</span> <span class="o">+</span> <span class="mi">1</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">grad_f</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="mi">2</span><span class="o">*</span><span class="n">x</span> <span class="o">+</span> <span class="mi">2</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">hess_f</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">2</span><span class="p">]])</span>  <span class="c1"># 二阶导数为常数2</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 运行牛顿法</span>
</span></span><span class="line"><span class="cl"><span class="n">x_opt</span><span class="p">,</span> <span class="n">history</span> <span class="o">=</span> <span class="n">newton_method</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">grad_f</span><span class="p">,</span> <span class="n">hess_f</span><span class="p">,</span> <span class="n">x0</span><span class="o">=</span><span class="mf">5.0</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;最优解: x = </span><span class="si">{</span><span class="n">x_opt</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;最优值: f(x) = </span><span class="si">{</span><span class="n">f</span><span class="p">(</span><span class="n">x_opt</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span></code></pre></div><h2 id="局限性">局限性</h2>
<ol>
<li><strong>计算成本</strong>：需要计算和存储Hessian矩阵</li>
<li><strong>存储需求</strong>：对于高维问题，Hessian矩阵存储成本高</li>
<li><strong>数值稳定性</strong>：Hessian矩阵可能不可逆或病态</li>
</ol>
<h2 id="改进方法">改进方法</h2>
<h3 id="拟牛顿法">拟牛顿法</h3>
<p>拟牛顿法通过近似Hessian矩阵来避免直接计算：</p></p>
            <div class="post-tags">
                
                <span class="tag">牛顿法</span>
                
                <span class="tag">二阶优化</span>
                
                <span class="tag">拟牛顿法</span>
                
                <span class="tag">Hessian矩阵</span>
                
            </div>
        </article>
        
    </div>
</div>

        </div>
    </main>

    <footer class="site-footer">
        <div class="container">
            <p>&copy; 2025 Claire的技术学习笔记. All rights reserved.</p>
        </div>
    </footer>
</body>
</html>
