<!DOCTYPE html>
<html lang="zh-cn">
<head><script src="/blog/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=blog/livereload" data-no-instant defer></script>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>梯度下降算法详解 - Claire的技术学习笔记</title>
    
    
    <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\\(', '\\)']],
                displayMath: [['$$', '$$'], ['\\[', '\\]']],
                processEscapes: true,
                processEnvironments: true
            },
            options: {
                skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
            },
            chtml: {
                linebreaks: { automatic: true }
            }
        };
    </script>
    
    
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    
    
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-tomorrow.min.css" rel="stylesheet" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>
    
    
    <link rel="stylesheet" href="http://localhost:1313/blog/css/style.css">
    
    
    <link rel="icon" type="image/x-icon" href="http://localhost:1313/blog/favicon.ico">
</head>
<body>
    <header class="site-header">
        <div class="container">
            <nav class="navbar">
                <div class="navbar-brand">
                    <a href="http://localhost:1313/blog/" class="navbar-item">
                        <h1 class="title">Claire的技术学习笔记</h1>
                    </a>
                </div>
                <div class="navbar-menu">
                    <a href="http://localhost:1313/blog/" class="navbar-item">首页</a>
                    <a href="http://localhost:1313/blog/categories" class="navbar-item">分类</a>
                    <a href="http://localhost:1313/blog/tags" class="navbar-item">标签</a>
                    <a href="http://localhost:1313/blog/about" class="navbar-item">关于</a>
                </div>
            </nav>
        </div>
    </header>

    <main class="site-main">
        <div class="container">
            
<div class="post-layout">
    
    <aside class="toc-sidebar">
        <div class="toc-container">
            <h3 class="toc-title">📋 目录</h3>
            <div class="toc-content" id="toc">
                
            </div>
        </div>
    </aside>

    
    <article class="post">
        <header class="post-header">
            <h1 class="post-title">梯度下降算法详解</h1>
            <div class="post-meta">
                <time datetime="2024-01-15">2024年1月15日</time>
                
                <span class="category">数值优化</span>
                
            </div>
            
            <div class="post-tags">
                
                <span class="tag">梯度下降</span>
                
                <span class="tag">机器学习</span>
                
                <span class="tag">一阶优化</span>
                
                <span class="tag">收敛性分析</span>
                
            </div>
            
        </header>

        <div class="post-content" id="post-content">
            <h1 id="梯度下降算法详解">梯度下降算法详解</h1>
<p>梯度下降是数值优化中最基础和重要的算法之一。本文将详细介绍梯度下降的原理、实现和应用。</p>
<h2 id="算法原理">算法原理</h2>
<p>梯度下降的核心思想是沿着目标函数的负梯度方向进行搜索，以找到函数的局部最小值。</p>
<p>对于目标函数 $f(x)$，梯度下降的更新公式为：</p>
<p>$$x_{k+1} = x_k - \alpha \nabla f(x_k)$$</p>
<p>其中：</p>
<ul>
<li>$x_k$ 是第 $k$ 次迭代的参数值</li>
<li>$\alpha$ 是学习率</li>
<li>$\nabla f(x_k)$ 是函数在 $x_k$ 处的梯度</li>
</ul>
<h2 id="代码实现">代码实现</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">gradient_descent</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">grad_f</span><span class="p">,</span> <span class="n">x0</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;&#34;&#34;
</span></span></span><span class="line"><span class="cl"><span class="s2">    梯度下降算法实现
</span></span></span><span class="line"><span class="cl"><span class="s2">    
</span></span></span><span class="line"><span class="cl"><span class="s2">    参数:
</span></span></span><span class="line"><span class="cl"><span class="s2">    f: 目标函数
</span></span></span><span class="line"><span class="cl"><span class="s2">    grad_f: 梯度函数
</span></span></span><span class="line"><span class="cl"><span class="s2">    x0: 初始点
</span></span></span><span class="line"><span class="cl"><span class="s2">    alpha: 学习率
</span></span></span><span class="line"><span class="cl"><span class="s2">    max_iter: 最大迭代次数
</span></span></span><span class="line"><span class="cl"><span class="s2">    tol: 收敛容差
</span></span></span><span class="line"><span class="cl"><span class="s2">    
</span></span></span><span class="line"><span class="cl"><span class="s2">    返回:
</span></span></span><span class="line"><span class="cl"><span class="s2">    x: 最优解
</span></span></span><span class="line"><span class="cl"><span class="s2">    history: 迭代历史
</span></span></span><span class="line"><span class="cl"><span class="s2">    &#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">x0</span>
</span></span><span class="line"><span class="cl">    <span class="n">history</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="o">.</span><span class="n">copy</span><span class="p">()]</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_iter</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="n">grad</span> <span class="o">=</span> <span class="n">grad_f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">x_new</span> <span class="o">=</span> <span class="n">x</span> <span class="o">-</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">grad</span>
</span></span><span class="line"><span class="cl">        
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">x_new</span> <span class="o">-</span> <span class="n">x</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">tol</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="k">break</span>
</span></span><span class="line"><span class="cl">            
</span></span><span class="line"><span class="cl">        <span class="n">x</span> <span class="o">=</span> <span class="n">x_new</span>
</span></span><span class="line"><span class="cl">        <span class="n">history</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">copy</span><span class="p">())</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">x</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">history</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 示例：最小化 f(x) = x^2 + 2x + 1</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">x</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="mi">2</span><span class="o">*</span><span class="n">x</span> <span class="o">+</span> <span class="mi">1</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">grad_f</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="mi">2</span><span class="o">*</span><span class="n">x</span> <span class="o">+</span> <span class="mi">2</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 运行梯度下降</span>
</span></span><span class="line"><span class="cl"><span class="n">x_opt</span><span class="p">,</span> <span class="n">history</span> <span class="o">=</span> <span class="n">gradient_descent</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">grad_f</span><span class="p">,</span> <span class="n">x0</span><span class="o">=</span><span class="mf">5.0</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;最优解: x = </span><span class="si">{</span><span class="n">x_opt</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;最优值: f(x) = </span><span class="si">{</span><span class="n">f</span><span class="p">(</span><span class="n">x_opt</span><span class="p">)</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span></code></pre></div><h2 id="收敛性分析">收敛性分析</h2>
<p>梯度下降的收敛性取决于以下几个因素：</p>
<ol>
<li><strong>学习率选择</strong>：学习率过大可能导致发散，过小则收敛缓慢</li>
<li><strong>函数性质</strong>：凸函数保证收敛到全局最优解</li>
<li><strong>初始点选择</strong>：影响收敛速度和最终解的质量</li>
</ol>
<h2 id="变体算法">变体算法</h2>
<h3 id="随机梯度下降-sgd">随机梯度下降 (SGD)</h3>
<p>对于大规模数据集，可以使用随机梯度下降：</p>
<p>$$x_{k+1} = x_k - \alpha \nabla f_i(x_k)$$</p>
<p>其中 $f_i$ 是第 $i$ 个样本的损失函数。</p>
<h3 id="动量法">动量法</h3>
<p>动量法通过引入动量项来加速收敛：</p>
<p>$$v_{k+1} = \beta v_k + \alpha \nabla f(x_k)$$
$$x_{k+1} = x_k - v_{k+1}$$</p>
<p>其中 $\beta$ 是动量系数。</p>
<h2 id="总结">总结</h2>
<p>梯度下降是数值优化的基础算法，理解其原理和实现对于深入学习机器学习算法至关重要。在实际应用中，需要根据具体问题选择合适的变体和参数设置。</p>

        </div>

        <footer class="post-footer">
            <div class="post-navigation">
                
                
                <a href="/blog/posts/newton-method/" class="next-post">
                    牛顿法优化算法 →
                </a>
                
            </div>
        </footer>
    </article>
</div>


<script>
document.addEventListener('DOMContentLoaded', function() {
    generateTOC();
    handleTOCScroll();
});

function generateTOC() {
    const content = document.getElementById('post-content');
    const toc = document.getElementById('toc');
    const headings = content.querySelectorAll('h1, h2, h3, h4, h5, h6');
    
    if (headings.length === 0) {
        document.querySelector('.toc-sidebar').style.display = 'none';
        document.querySelector('.post').style.marginLeft = '0';
        return;
    }
    
    let tocHTML = '<ul class="toc-list">';
    let currentLevel = 0;
    
    headings.forEach((heading, index) => {
        const level = parseInt(heading.tagName.charAt(1));
        const text = heading.textContent;
        const id = 'heading-' + index;
        
        
        heading.id = id;
        
        
        if (level > currentLevel) {
            for (let i = currentLevel; i < level; i++) {
                if (i > 0) tocHTML += '<ul class="toc-list">';
            }
        } else if (level < currentLevel) {
            for (let i = currentLevel; i > level; i--) {
                tocHTML += '</ul>';
            }
        }
        
        tocHTML += `<li class="toc-item toc-level-${level}">
                      <a href="#${id}" class="toc-link" data-target="${id}">${text}</a>
                    </li>`;
        
        currentLevel = level;
    });
    
    
    for (let i = 0; i < currentLevel; i++) {
        tocHTML += '</ul>';
    }
    
    toc.innerHTML = tocHTML;
    
    
    document.querySelectorAll('.toc-link').forEach(link => {
        link.addEventListener('click', function(e) {
            e.preventDefault();
            const targetId = this.getAttribute('data-target');
            const targetElement = document.getElementById(targetId);
            if (targetElement) {
                targetElement.scrollIntoView({ behavior: 'smooth' });
                
                
                document.querySelectorAll('.toc-link').forEach(l => l.classList.remove('active'));
                this.classList.add('active');
            }
        });
    });
}

function handleTOCScroll() {
    const headings = document.querySelectorAll('#post-content h1, #post-content h2, #post-content h3, #post-content h4, #post-content h5, #post-content h6');
    const tocLinks = document.querySelectorAll('.toc-link');
    
    if (headings.length === 0) return;
    
    window.addEventListener('scroll', function() {
        let currentHeading = '';
        
        headings.forEach(heading => {
            const rect = heading.getBoundingClientRect();
            if (rect.top <= 100) {
                currentHeading = heading.id;
            }
        });
        
        tocLinks.forEach(link => {
            link.classList.remove('active');
            if (link.getAttribute('data-target') === currentHeading) {
                link.classList.add('active');
            }
        });
    });
}
</script>

        </div>
    </main>

    <footer class="site-footer">
        <div class="container">
            <p>&copy; 2025 Claire的技术学习笔记. All rights reserved.</p>
        </div>
    </footer>

    
    <button id="back-to-top" class="back-to-top-btn" title="回到顶部">
        <svg width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg">
            <path d="M12 4L4 12H8V20H16V12H20L12 4Z" fill="currentColor"/>
        </svg>
    </button>

    
    <script>
        document.addEventListener('DOMContentLoaded', function() {
            const backToTopBtn = document.getElementById('back-to-top');
            
            
            window.addEventListener('scroll', function() {
                if (window.pageYOffset > 300) {
                    backToTopBtn.classList.add('show');
                } else {
                    backToTopBtn.classList.remove('show');
                }
            });
            
            
            backToTopBtn.addEventListener('click', function() {
                window.scrollTo({
                    top: 0,
                    behavior: 'smooth'
                });
            });
        });
    </script>
</body>
</html>
