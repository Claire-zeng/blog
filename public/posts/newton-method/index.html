<!DOCTYPE html>
<html lang="zh-cn">
<head><script src="/blog/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=blog/livereload" data-no-instant defer></script>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>牛顿法优化算法 - Claire的技术学习笔记</title>
    
    
    <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\\(', '\\)']],
                displayMath: [['$$', '$$'], ['\\[', '\\]']],
                processEscapes: true,
                processEnvironments: true
            },
            options: {
                skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
            },
            chtml: {
                linebreaks: { automatic: true }
            }
        };
    </script>
    
    
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    
    
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-tomorrow.min.css" rel="stylesheet" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>
    
    
    <link rel="stylesheet" href="http://localhost:1313/blog/css/style.css">
    
    
    <link rel="icon" type="image/x-icon" href="http://localhost:1313/blog/favicon.ico">
</head>
<body>
    <header class="site-header">
        <div class="container">
            <nav class="navbar">
                <div class="navbar-brand">
                    <a href="http://localhost:1313/blog/" class="navbar-item">
                        <h1 class="title">Claire的技术学习笔记</h1>
                    </a>
                </div>
                <div class="navbar-menu">
                    <a href="http://localhost:1313/blog/" class="navbar-item">首页</a>
                    <a href="http://localhost:1313/blog/categories" class="navbar-item">分类</a>
                    <a href="http://localhost:1313/blog/tags" class="navbar-item">标签</a>
                    <a href="http://localhost:1313/blog/about" class="navbar-item">关于</a>
                </div>
            </nav>
        </div>
    </header>

    <main class="site-main">
        <div class="container">
            
<div class="post-layout">
    
    <aside class="toc-sidebar">
        <div class="toc-container">
            <h3 class="toc-title">📋 目录</h3>
            <div class="toc-content" id="toc">
                
            </div>
        </div>
    </aside>

    
    <article class="post">
        <header class="post-header">
            <h1 class="post-title">牛顿法优化算法</h1>
            <div class="post-meta">
                <time datetime="2024-01-16">2024年1月16日</time>
                
                <span class="category">数值优化</span>
                
            </div>
            
            <div class="post-tags">
                
                <span class="tag">牛顿法</span>
                
                <span class="tag">二阶优化</span>
                
                <span class="tag">拟牛顿法</span>
                
                <span class="tag">Hessian矩阵</span>
                
            </div>
            
        </header>

        <div class="post-content" id="post-content">
            <h1 id="牛顿法优化算法">牛顿法优化算法</h1>
<p>牛顿法是一种基于二阶信息的优化算法，相比梯度下降具有更快的收敛速度。</p>
<h2 id="算法原理">算法原理</h2>
<p>牛顿法利用函数的二阶导数信息来构造更好的搜索方向。对于目标函数 $f(x)$，牛顿法的更新公式为：</p>
<p>$$x_{k+1} = x_k - H^{-1}(x_k) \nabla f(x_k)$$</p>
<p>其中：</p>
<ul>
<li>$H(x_k)$ 是函数在 $x_k$ 处的Hessian矩阵</li>
<li>$\nabla f(x_k)$ 是梯度向量</li>
</ul>
<h2 id="优势与特点">优势与特点</h2>
<ol>
<li><strong>二次收敛</strong>：在最优解附近具有二次收敛速度</li>
<li><strong>二阶信息</strong>：利用Hessian矩阵提供更精确的局部信息</li>
<li><strong>自适应步长</strong>：不需要手动设置学习率</li>
</ol>
<h2 id="代码实现">代码实现</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">scipy.linalg</span> <span class="kn">import</span> <span class="n">inv</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">newton_method</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">grad_f</span><span class="p">,</span> <span class="n">hess_f</span><span class="p">,</span> <span class="n">x0</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;&#34;&#34;
</span></span></span><span class="line"><span class="cl"><span class="s2">    牛顿法实现
</span></span></span><span class="line"><span class="cl"><span class="s2">    
</span></span></span><span class="line"><span class="cl"><span class="s2">    参数:
</span></span></span><span class="line"><span class="cl"><span class="s2">    f: 目标函数
</span></span></span><span class="line"><span class="cl"><span class="s2">    grad_f: 梯度函数
</span></span></span><span class="line"><span class="cl"><span class="s2">    hess_f: Hessian函数
</span></span></span><span class="line"><span class="cl"><span class="s2">    x0: 初始点
</span></span></span><span class="line"><span class="cl"><span class="s2">    max_iter: 最大迭代次数
</span></span></span><span class="line"><span class="cl"><span class="s2">    tol: 收敛容差
</span></span></span><span class="line"><span class="cl"><span class="s2">    &#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">x0</span>
</span></span><span class="line"><span class="cl">    <span class="n">history</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="o">.</span><span class="n">copy</span><span class="p">()]</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_iter</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="n">grad</span> <span class="o">=</span> <span class="n">grad_f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">hess</span> <span class="o">=</span> <span class="n">hess_f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        
</span></span><span class="line"><span class="cl">        <span class="c1"># 求解线性方程组 H(x) * d = -grad(x)</span>
</span></span><span class="line"><span class="cl">        <span class="k">try</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">d</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">hess</span><span class="p">,</span> <span class="o">-</span><span class="n">grad</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="k">except</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">LinAlgError</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># 如果Hessian不可逆，使用伪逆</span>
</span></span><span class="line"><span class="cl">            <span class="n">d</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">pinv</span><span class="p">(</span><span class="n">hess</span><span class="p">)</span> <span class="o">@</span> <span class="n">grad</span>
</span></span><span class="line"><span class="cl">        
</span></span><span class="line"><span class="cl">        <span class="n">x_new</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">d</span>
</span></span><span class="line"><span class="cl">        
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">x_new</span> <span class="o">-</span> <span class="n">x</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">tol</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="k">break</span>
</span></span><span class="line"><span class="cl">            
</span></span><span class="line"><span class="cl">        <span class="n">x</span> <span class="o">=</span> <span class="n">x_new</span>
</span></span><span class="line"><span class="cl">        <span class="n">history</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">copy</span><span class="p">())</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">x</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">history</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 示例：最小化 f(x) = x^2 + 2x + 1</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">x</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="mi">2</span><span class="o">*</span><span class="n">x</span> <span class="o">+</span> <span class="mi">1</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">grad_f</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="mi">2</span><span class="o">*</span><span class="n">x</span> <span class="o">+</span> <span class="mi">2</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">hess_f</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">2</span><span class="p">]])</span>  <span class="c1"># 二阶导数为常数2</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 运行牛顿法</span>
</span></span><span class="line"><span class="cl"><span class="n">x_opt</span><span class="p">,</span> <span class="n">history</span> <span class="o">=</span> <span class="n">newton_method</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">grad_f</span><span class="p">,</span> <span class="n">hess_f</span><span class="p">,</span> <span class="n">x0</span><span class="o">=</span><span class="mf">5.0</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;最优解: x = </span><span class="si">{</span><span class="n">x_opt</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;最优值: f(x) = </span><span class="si">{</span><span class="n">f</span><span class="p">(</span><span class="n">x_opt</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span></code></pre></div><h2 id="局限性">局限性</h2>
<ol>
<li><strong>计算成本</strong>：需要计算和存储Hessian矩阵</li>
<li><strong>存储需求</strong>：对于高维问题，Hessian矩阵存储成本高</li>
<li><strong>数值稳定性</strong>：Hessian矩阵可能不可逆或病态</li>
</ol>
<h2 id="改进方法">改进方法</h2>
<h3 id="拟牛顿法">拟牛顿法</h3>
<p>拟牛顿法通过近似Hessian矩阵来避免直接计算：</p>
<ul>
<li><strong>BFGS算法</strong>：最常用的拟牛顿法</li>
<li><strong>DFP算法</strong>：另一种经典的拟牛顿法</li>
<li><strong>L-BFGS</strong>：适用于大规模问题的内存友好版本</li>
</ul>
<h2 id="总结">总结</h2>
<p>牛顿法在函数性质良好时具有优秀的收敛性能，但在实际应用中需要考虑计算成本和数值稳定性问题。</p>

        </div>

        <footer class="post-footer">
            <div class="post-navigation">
                
                <a href="/blog/posts/gradient-descent/" class="prev-post">
                    ← 梯度下降算法详解
                </a>
                
                
                <a href="/blog/posts/%E6%97%A0%E7%BA%A6%E6%9D%9F%E4%BC%98%E5%8C%96%E5%9F%BA%E7%A1%80%E4%B8%80/" class="next-post">
                    无约束优化基础(一) →
                </a>
                
            </div>
        </footer>
    </article>
</div>


<script>
document.addEventListener('DOMContentLoaded', function() {
    generateTOC();
    handleTOCScroll();
});

function generateTOC() {
    const content = document.getElementById('post-content');
    const toc = document.getElementById('toc');
    const headings = content.querySelectorAll('h1, h2, h3, h4, h5, h6');
    
    if (headings.length === 0) {
        document.querySelector('.toc-sidebar').style.display = 'none';
        document.querySelector('.post').style.marginLeft = '0';
        return;
    }
    
    let tocHTML = '<ul class="toc-list">';
    let currentLevel = 0;
    
    headings.forEach((heading, index) => {
        const level = parseInt(heading.tagName.charAt(1));
        const text = heading.textContent;
        const id = 'heading-' + index;
        
        
        heading.id = id;
        
        
        if (level > currentLevel) {
            for (let i = currentLevel; i < level; i++) {
                if (i > 0) tocHTML += '<ul class="toc-list">';
            }
        } else if (level < currentLevel) {
            for (let i = currentLevel; i > level; i--) {
                tocHTML += '</ul>';
            }
        }
        
        tocHTML += `<li class="toc-item toc-level-${level}">
                      <a href="#${id}" class="toc-link" data-target="${id}">${text}</a>
                    </li>`;
        
        currentLevel = level;
    });
    
    
    for (let i = 0; i < currentLevel; i++) {
        tocHTML += '</ul>';
    }
    
    toc.innerHTML = tocHTML;
    
    
    document.querySelectorAll('.toc-link').forEach(link => {
        link.addEventListener('click', function(e) {
            e.preventDefault();
            const targetId = this.getAttribute('data-target');
            const targetElement = document.getElementById(targetId);
            if (targetElement) {
                targetElement.scrollIntoView({ behavior: 'smooth' });
                
                
                document.querySelectorAll('.toc-link').forEach(l => l.classList.remove('active'));
                this.classList.add('active');
            }
        });
    });
}

function handleTOCScroll() {
    const headings = document.querySelectorAll('#post-content h1, #post-content h2, #post-content h3, #post-content h4, #post-content h5, #post-content h6');
    const tocLinks = document.querySelectorAll('.toc-link');
    
    if (headings.length === 0) return;
    
    window.addEventListener('scroll', function() {
        let currentHeading = '';
        
        headings.forEach(heading => {
            const rect = heading.getBoundingClientRect();
            if (rect.top <= 100) {
                currentHeading = heading.id;
            }
        });
        
        tocLinks.forEach(link => {
            link.classList.remove('active');
            if (link.getAttribute('data-target') === currentHeading) {
                link.classList.add('active');
            }
        });
    });
}
</script>

        </div>
    </main>

    <footer class="site-footer">
        <div class="container">
            <p>&copy; 2025 Claire的技术学习笔记. All rights reserved.</p>
        </div>
    </footer>

    
    <button id="back-to-top" class="back-to-top-btn" title="回到顶部">
        <svg width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg">
            <path d="M12 4L4 12H8V20H16V12H20L12 4Z" fill="currentColor"/>
        </svg>
    </button>

    
    <script>
        document.addEventListener('DOMContentLoaded', function() {
            const backToTopBtn = document.getElementById('back-to-top');
            
            
            window.addEventListener('scroll', function() {
                if (window.pageYOffset > 300) {
                    backToTopBtn.classList.add('show');
                } else {
                    backToTopBtn.classList.remove('show');
                }
            });
            
            
            backToTopBtn.addEventListener('click', function() {
                window.scrollTo({
                    top: 0,
                    behavior: 'smooth'
                });
            });
        });
    </script>
</body>
</html>
